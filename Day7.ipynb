{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"AV_Logo.png\" style=\"width: 200px;height: 75px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "--------------\n",
    "* [Evaluation of Predictive Models](Evaluation-of-Predictive-Models)\n",
    "* [Types of Predictive Models](Types-of-Predictive-Models)\n",
    "* [Confusion Matrix](Confusion-Matrix)\n",
    "* [Area Under the ROC curve (AUC – ROC)](Area-Under-the-ROC-curve-(AUC-–-ROC))\n",
    "* [Cross Validation](Cross-Validation)\n",
    "* [RMSE](Root-Mean-Squared-Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive Modeling works on constructive feedback principle. You build a model - get feedback from metrics - make improvements and continue until you achieve a desirable accuracy. Evaluation metrics explain the performance of a model. An important aspect of evaluation metrics is their capability to discriminate among model results. Simply, building a predictive model should not be your motive. But, creating and selecting a model which gives high accuracy on out of sample data. Hence, it is crucial to check accuracy of the model prior to computing predicted values.\n",
    "\n",
    "We consider different kinds of metrics to evaluate our models. The choice of metric completely depends on the type of model and the implementation plan of the model. After you are finished building your model the below metrics will help you in evaluating your model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we talk about predictive models, we are talking either about a regression model (continuous output) or a classification model (nominal or binary output). The evaluation metrics used in each of these models are different.\n",
    "\n",
    "In classification problems, we use two types of algorithms (dependent on the kind of output it creates):\n",
    "\n",
    "* **Class output** : For instance, in a binary classification problem, the outputs will be either 0 or 1. \n",
    "\n",
    "* **Probability output** : For instance, in a binary classification problem, the outputs will be between 0 and 1. Converting probability outputs to class output is just a matter of creating a threshold probability.\n",
    "\n",
    "In regression problems, we have a continuous value as output. This requires no further treatment.\n",
    "\n",
    "Let's see some evaluation techniques for various predictive models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is an N X N matrix, where N is the number of classes being predicted. For the problem in hand, we have N=2, and hence we get a 2 X 2 matrix. Here are a few definitions, you need to remember for a confusion matrix :\n",
    "\n",
    "* **Accuracy** : Proportion of the total number of predictions that were correct.\n",
    "* **Positive Predictive Value or Precision** : Proportion of positive cases that were correctly identified.\n",
    "* **Negative Predictive Value** : Proportion of negative cases that were correctly identified.\n",
    "* **Sensitivity or Recall** : Proportion of actual positive cases which are correctly identified.\n",
    "* **Specificity** : Proportion of actual negative cases which are correctly identified.\n",
    "\n",
    "<img src=\"Confusion_matrix.png\" style=\"width: 500px;height: 150px\">\n",
    "\n",
    "<img src=\"pivottable.png\" style=\"width: 300px;height: 150px\">\n",
    "\n",
    "Consider the above confusion matrix, the accuracy comes out to be 88%. As you can see from the above two tables, the Positive predictive Value is high, but negative predictive value is quite low. Same holds for Senstivity and Specificity. This is primarily driven by the threshold value we have chosen. If we decrease our threshold value, the two pairs of starkly different numbers will come closer.\n",
    "\n",
    "In general we are concerned with one of the above defined metric. For instance, in a pharmaceutical company, they will be more concerned with minimal wrong positive diagnosis. Hence, they will be more concerned about high Specificity. On the other hand an attrition model will be more concerned with Senstivity. Confusion matrix are generally used only with class output mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define logistic regression\n",
    "logReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('winequality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W0001</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W0002</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W0003</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W0004</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W0005</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0  W0001            7.0              0.27         0.36            20.7   \n",
       "1  W0002            6.3              0.30         0.34             1.6   \n",
       "2  W0003            8.1              0.28         0.40             6.9   \n",
       "3  W0004            7.2              0.23         0.32             8.5   \n",
       "4  W0005            7.2              0.23         0.32             8.5   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.045                 45.0                 170.0   1.0010  3.00   \n",
       "1      0.049                 14.0                 132.0   0.9940  3.30   \n",
       "2      0.050                 30.0                  97.0   0.9951  3.26   \n",
       "3      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "4      0.058                 47.0                 186.0   0.9956  3.19   \n",
       "\n",
       "   sulphates  alcohol  quality  \n",
       "0       0.45      8.8        2  \n",
       "1        NaN      9.5        2  \n",
       "2        NaN     10.1        2  \n",
       "3       0.40      9.9        2  \n",
       "4       0.40      9.9        2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for simplicity, we can convert the problem into a binary classification problem\n",
    "## the values of target \"quality\" will then be [0, 1] instead of [1, 2]\n",
    "data.loc[(data.quality == 2), 'quality'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for now, select only two features\n",
    "X = data[['fixed acidity', 'volatile acidity']]\n",
    "y = data.quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "logReg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get predictions\n",
    "pred = logReg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual: 0</th>\n",
       "      <th>Actual: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted: 0</th>\n",
       "      <td>3104</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted: 1</th>\n",
       "      <td>1450</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Actual: 0  Actual: 1\n",
       "Predicted: 0       3104        154\n",
       "Predicted: 1       1450        190"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get confusion matrix\n",
    "C = confusion_matrix(y, pred)\n",
    "pd.DataFrame(C, index=['Predicted: 0', 'Predicted: 1'], columns=['Actual: 0', 'Actual: 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAI2CAYAAACrNnceAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b1a1373860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to print a more intuitive confusion matrix, we are loading a custom \n",
    "## function we defined ourselves. Go through \"plot_matrix.py\" file \n",
    "## if you are curious\n",
    "from plot_matrix import show_confusion_matrix\n",
    "show_confusion_matrix(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "\n",
    "Q1. Load dataset 'student.csv', select features 'age', 'studytime' and then print confusion matrix for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under the ROC curve (AUC – ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first try to understand what is ROC (Receiver operating characteristic) curve. If we look at the confusion matrix below, we observe that for a probabilistic model, we get different value for each metric.\n",
    "\n",
    "<img src=\"Confusion_matrix.png\" style=\"width: 500px;height: 150px\">\n",
    "\n",
    "Hence, for each sensitivity, we get a different specificity.The two vary as follows:\n",
    "\n",
    "<img src=\"curves.png\" style=\"width: 300px;height: 150px\">\n",
    "\n",
    "The ROC curve is the plot between sensitivity and (1- specificity). (1- specificity) is also known as false positive rate and sensitivity is also known as True Positive rate. Following is the ROC curve for the case in hand.\n",
    "\n",
    "<img src=\"ROC.png\" style=\"width: 400px;height: 250px\">\n",
    "\n",
    "Let’s take an example of threshold = 0.5 (refer to confusion matrix). Here is the confusion matrix :\n",
    "\n",
    "<img src=\"pivottable.png\" style=\"width: 300px;height: 150px\">\n",
    "\n",
    "As you can see, the sensitivity at this threshold is 99.6% and the (1-specificity) is ~60%. This coordinate becomes on point in our ROC curve. To bring this curve down to a single number, we find the area under this curve (AUC).\n",
    "\n",
    "Note that the area of entire square is 1*1 = 1. Hence AUC itself is the ratio under the curve and the total area. For the case in hand, we get AUC ROC as 96.4%. Following are a few thumb rules:\n",
    "\n",
    "* 0.90-1 = excellent (A)\n",
    "* 0.80-0.90 = good (B)\n",
    "* 0.70-0.80 = fair (C)\n",
    "* 0.60-0.70 = poor (D)\n",
    "* 0.50-0.60 = fail (F)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points to Remember:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For a model which gives class as output, will be represented as a single point in ROC plot.\n",
    "\n",
    "2. Such models cannot be compared with each other as the judgement needs to be taken on a single metric and not using multiple metrics. For instance, model with parameters (0.2,0.8) and model with parameter (0.8,0.2) can be coming out of the same model, hence these metrics should not be directly compared.\n",
    "\n",
    "3. In case of probabilistic model, we were fortunate enough to get a single number which was AUC-ROC. But still, we need to look at the entire curve to make conclusive decisions. It is also possible that one model performs better in some region and other performs better in other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: here we would have to predict probabilities instead of binary classes\n",
    "pred = logReg.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.67115117,  0.32884883],\n",
       "       [ 0.67565876,  0.32434124],\n",
       "       [ 0.60649045,  0.39350955],\n",
       "       ..., \n",
       "       [ 0.72147312,  0.27852688],\n",
       "       [ 0.72111208,  0.27888792],\n",
       "       [ 0.76677055,  0.23322945]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65084650915569919"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, pred[:, 1], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "\n",
    "Q1. Load dataset 'student.csv', select features 'age', 'studytime' and then print roc_auc_score for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE(Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE is the most popular evaluation metric used in regression problems. It follows an assumption that error are unbiased and follow a normal distribution. Here are the key points to consider on RMSE:\n",
    "\n",
    "* The power of ‘square root’  empowers this metric to show large number deviations.\n",
    "* The ‘squared’ nature of this metric helps to deliver more robust results which prevents cancelling the positive and negative error values. In other words, this metric aptly displays the plausible magnitude of error term.\n",
    "* It avoids the use of absolute error values which is highly undesirable in mathematical calculations.\n",
    "* When we have more samples, reconstructing the error distribution using RMSE is considered to be more reliable.\n",
    "* RMSE is highly affected by outlier values. Hence, make sure you’ve removed outliers from your data set prior to using this metric.\n",
    "* As compared to mean absolute error, RMSE gives higher weightage and punishes large errors.\n",
    "\n",
    "RMSE metric is given by:\n",
    "\n",
    "<img src=\"rmse.png\" style=\"width: 250px;height: 100px\">\n",
    "\n",
    "where, N is Total Number of Observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linReg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset for practice hackathon bike sharing (link: https://datahack.analyticsvidhya.com/contest/datahack-hour-bike-sharing/)\n",
    "data = pd.read_csv('train_ysMSKmQ.csv')\n",
    "test = pd.read_csv('test_uLBXQQR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01/01/11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>01/01/11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>01/01/11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>01/01/11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>01/01/11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant    dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  01/01/11       1   0     1   0        0        6           0   \n",
       "1        2  01/01/11       1   0     1   1        0        6           0   \n",
       "2        3  01/01/11       1   0     1   2        0        6           0   \n",
       "3        4  01/01/11       1   0     1   3        0        6           0   \n",
       "4        5  01/01/11       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0   16  \n",
       "1           1  0.22  0.2727  0.80        0.0   40  \n",
       "2           1  0.22  0.2727  0.80        0.0   32  \n",
       "3           1  0.24  0.2879  0.75        0.0   13  \n",
       "4           1  0.24  0.2879  0.75        0.0    1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop(['cnt', 'dteday'], axis=1)\n",
    "y = data.cnt\n",
    "\n",
    "X_test = test.drop(['dteday'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linReg.fit(X[['season']], y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = linReg.predict(X[['season']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159.95424422312684"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "\n",
    "Q1. Calculate RMSE for each single feature and find which gives minimum RMSE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's submit our model and check the result on datahack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = linReg.predict(X_test[['season']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13036</td>\n",
       "      <td>179.928897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13037</td>\n",
       "      <td>179.928897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13038</td>\n",
       "      <td>179.928897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13039</td>\n",
       "      <td>179.928897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13040</td>\n",
       "      <td>179.928897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant         cnt\n",
       "0    13036  179.928897\n",
       "1    13037  179.928897\n",
       "2    13038  179.928897\n",
       "3    13039  179.928897\n",
       "4    13040  179.928897"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create submission file\n",
    "submission = pd.DataFrame(data=[], columns=['instant', 'cnt'])\n",
    "submission.instant = test.instant; submission.cnt = pred\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that your testing score and training score is different. This means that however better score you get by applying feature engineering, etc on train set, it may not necessarily be similarly replicated on test set. So how do we ensure this? (Hint: It can be done through cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though, cross validation isn’t a really a evaluation metric which is used openly to communicate model accuracy. But, the result of cross validation provides good enough intuitive result to generalize the performance of a model.\n",
    "\n",
    "Using the metrics defined above, we might still have an over fit model where we may not know if the model is generalised or not.\n",
    "\n",
    "Cross Validation is mainly used to detect and overcome overfitting. Over-fitting is nothing but when your model becomes highly complex that it starts capturing noise. This ‘noise’ adds no value to model, but only inaccuracy. \n",
    "\n",
    "Cross Validation is one of the most important concepts in any type of data modeling. It simply says, try to leave a sample on which you do not train the model and test the model on this sample before finalizing the model.\n",
    "\n",
    "<img src=\"validation.png\" style=\"width: 250px;height: 350px\">\n",
    "\n",
    "Above diagram shows how to validate model with in-time sample. We simply divide the population into 2 samples, and build model on one sample. Rest of the population is used for in-time validation.\n",
    "\n",
    "Could there be a negative side of the above approach?\n",
    "\n",
    "I believe, a negative side of this approach is that we loose a good amount of data from training the model. Hence, the model is very high bias. And this won’t give best estimate for the coefficients. So what’s the next best option?\n",
    "\n",
    "What if, we make a 50:50 split of training population and the train on first 50 and validate on rest 50. Then, we train on the other 50, test on first 50. This way we train the model on the entire population, however on 50% in one go. This reduces bias because of sample selection to some extent but gives a smaller sample to train the model on. This approach is known as 2-fold cross validation.\n",
    "\n",
    "We can do a K-fold validation as well, where we would split the data into k parts. Train the model on k-1 sample splits of the data and validate on the remaining set and do it multiple times to be sure that there is no bias or overfitting. Below are the steps for K fold cross validation.  \n",
    "\n",
    "* Randomly split your entire dataset into \"k-folds\".\n",
    "* For each k folds in your dataset, build your model on k – 1 folds of the dataset. Then, test the model to check the effectiveness for kth fold.\n",
    "* Record the error you see on each of the predictions.\n",
    "* Repeat this until each of the k folds has served as the test set.\n",
    "* The average of your k recorded errors is called the cross-validation error and will serve as your performance metric for the model.\n",
    "\n",
    "<img src=\"kfolds.png\" style=\"width: 550px;height: 350px\">\n",
    "\n",
    "This is a 7-fold cross validation.\n",
    "\n",
    "Here’s what goes on behind the scene : we divide the entire population into 7 equal samples. Now we train models on 6 samples (Green boxes) and validate on 1 sample (grey box). Then, at the second iteration we train the model with a different sample held as validation. In 7 iterations, we have basically built model on each sample and held each of them as validation. This is a way to reduce the selection bias and reduce the variance in prediction power. Once we have all the 7 models, we take average of the error terms to find which of the models is best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faizy-PC\\Anaconda2\\envs\\dl_nd\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same as before\n",
    "data = pd.read_csv('winequality.csv')\n",
    "data.loc[(data.quality == 2), 'quality'] = 0\n",
    "X = data[['fixed acidity', 'volatile acidity']]\n",
    "y = data.quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.65649082,  0.63631135,  0.67334094,  0.59983   ,  0.67771206])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we get results for 5 folds of data\n",
    "cross_val_score(logReg, X, y, cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores of the folds may not necessarily be the same, because the data is different. We have to check that there's not muc variance in the scores. This is called stability of model. Less the variance, more stable your model is; And your aim is to get the most stable model, because you can rely on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "\n",
    "Q1. For which feature does the model remain most stable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for today!\n",
    "----------------\n",
    "-------------------------------\n",
    "<img src=\"AV_Datafest_logo.png\" style=\"width: 200px;height: 200px\"/>\n",
    "[www.analyticsvidhya.com](www.analyticsvidhya.com)\n",
    "\n",
    "DATAFEST 2017"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
